{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = [7,14,30,60]\n",
    "num_features = 8 #depends on how much features we have\n",
    "output_days = 7\n",
    "output_features = 2 #min and max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function definition\n",
    "def time_weighted_loss(y_true, y_pred, weights, lambda_=1.0, gamma=0.1):\n",
    "    \"\"\"\n",
    "    Time-weighted loss function for 7-day min and max price prediction.\n",
    "    \n",
    "    Args:\n",
    "        y_true (tf.Tensor): True values (concatenated min and max), shape (batch_size, 14).\n",
    "        y_pred (tf.Tensor): Predicted values (concatenated min and max), shape (batch_size, 14).\n",
    "        weights (list or tf.Tensor): Time-based weights for each day, shape (7,).\n",
    "        lambda_ (float): Weight for the min-max constraint penalty.\n",
    "        gamma (float): Weight for the temporal smoothness penalty.\n",
    "    \n",
    "    Returns:\n",
    "        tf.Tensor: Total loss value.\n",
    "    \"\"\"\n",
    "    # Split y_true and y_pred into min and max\n",
    "    y_true_min, y_true_max = y_true[:, 7:], y_true[:, :7]\n",
    "    y_pred_min, y_pred_max = y_pred[:, 7:], y_pred[:, :7]\n",
    "    \n",
    "    # Ensure weights are a tensor\n",
    "    weights = tf.convert_to_tensor(weights, dtype=tf.float32)\n",
    "    \n",
    "    # Time-weighted MSE for min and max\n",
    "    mse_min = tf.reduce_mean(weights * tf.square(y_true_min - y_pred_min))\n",
    "    mse_max = tf.reduce_mean(weights * tf.square(y_true_max - y_pred_max))\n",
    "    \n",
    "    # Time-weighted min-max constraint penalty\n",
    "    penalty = tf.reduce_sum(weights * tf.square(tf.maximum(0.0, y_pred_min - y_pred_max)))\n",
    "    \n",
    "    # Time-weighted temporal smoothness (optional)\n",
    "    smoothness_min = tf.reduce_sum(weights[1:] * tf.square(y_pred_min[:, 1:] - y_pred_min[:, :-1]))\n",
    "    smoothness_max = tf.reduce_sum(weights[1:] * tf.square(y_pred_max[:, 1:] - y_pred_max[:, :-1]))\n",
    "    \n",
    "    # Total loss\n",
    "    total_loss = (mse_min + mse_max) + lambda_ * penalty + gamma * (smoothness_min + smoothness_max)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "# Define weights (e.g., linear decay)\n",
    "weights = [1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4]\n",
    "\n",
    "# Wrap the loss function with fixed arguments\n",
    "custom_loss = partial(time_weighted_loss, weights=weights, lambda_=1.0, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_LSTM_model(window_size, num_features, output_days, output_features):\n",
    "    inputs = layers.Input(shape=(window_size, num_features))\n",
    "    \n",
    "    x = layers.LSTM(100, return_sequences=True)(inputs)\n",
    "    x = layers.LSTM(100)(x)\n",
    "    \n",
    "    x = layers.Dense(output_days * output_features)(x)  # Output for 7 days * 2 features (min and max)\n",
    "    \n",
    "    x = layers.Reshape((output_days, output_features))(x)\n",
    "    \n",
    "    model = models.Model(inputs, x)\n",
    "    function_name = baseline_LSTM_model.__name__\n",
    "    \n",
    "    return model, function_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_GRU_model(window_size, num_features, output_days, output_features):\n",
    "    inputs = layers.Input(shape=(window_size, num_features))\n",
    "    \n",
    "    x = layers.GRU(100, return_sequences=False)(inputs)\n",
    "    \n",
    "    x = layers.Dense(output_days * output_features)(x)  # Output for 7 days * 2 features (min and max)\n",
    "    \n",
    "    x = layers.Reshape((output_days, output_features))(x)\n",
    "    \n",
    "    model = models.Model(inputs, x)\n",
    "    function_name = baseline_GRU_model.__name__\n",
    "    \n",
    "    return model, function_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "CNN_LSTM mdoel is a combination of CNN and LSTM. CNN is used to extract the features from the input data and LSTM is used to support the sequence data.\n",
    "'''\n",
    "def CNN_LSTM_model(window_size, num_features, output_days, output_features):\n",
    "    inputs = layers.Input(shape=(window_size, num_features))\n",
    "    \n",
    "    x = layers.Conv1D(filters=64, kernel_size=2, activation='relu')(inputs)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Conv1D(filters=128, kernel_size=2, activation='relu')(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.LSTM(100, return_sequences=True)(x)\n",
    "    x = layers.LSTM(100)(x)\n",
    "    \n",
    "    x = layers.Dense(output_days * output_features)(x)  # 7 days * 2 targets (High, Low)\n",
    "    \n",
    "    x = layers.Reshape((output_days, output_features))(x)\n",
    "    \n",
    "    model = models.Model(inputs, x)\n",
    "    function_name = CNN_LSTM_model.__name__\n",
    "    \n",
    "    return model, function_name\n",
    "#can use KAN, Attenion layer to adjust the weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN + GRU model\n",
    "def CNN_GRU_model(window_size, num_features, output_days, output_features):\n",
    "    inputs = layers.Input(shape=(window_size, num_features))\n",
    "    \n",
    "    x = layers.Conv1D(filters=64, kernel_size=2, activation='relu')(inputs)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Conv1D(filters=128, kernel_size=2, activation='relu')(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.GRU(100, return_sequences=False)(x)\n",
    "    \n",
    "    x = layers.Dense(output_days * output_features)(x)  # Output for 7 days * 2 features (min and max)\n",
    "    \n",
    "    x = layers.Reshape((output_days, output_features))(x)\n",
    "    \n",
    "    model = models.Model(inputs, x)\n",
    "    function_name = CNN_GRU_model.__name__\n",
    "    \n",
    "    return model, function_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Attention\n",
    "def CNN_LSTM_SA_model(window_size, num_features, output_days, output_features):\n",
    "    inputs = layers.Input(shape=(window_size, num_features))\n",
    "    x = layers.Conv1D(filters=64, kernel_size=2, activation='relu')(inputs)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Conv1D(filters=128, kernel_size=2, activation='relu')(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.LSTM(100, return_sequences=True)(x)\n",
    "    x = layers.LSTM(100, return_sequences=True)(x)\n",
    "    \n",
    "    # Attention mechanism\n",
    "    attention = Attention()([x, x])\n",
    "    x = layers.Concatenate()([x, attention])\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    x = layers.Dense(output_days*output_features)(x)\n",
    "    outputs = layers.Reshape((output_days, output_features))(x)\n",
    "    \n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    function_name = CNN_LSTM_SA_model.__name__\n",
    "    return model, function_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_GRU_SA_model(window_size, num_features, output_days, output_features):\n",
    "    inputs = layers.Input(shape=(window_size, num_features))\n",
    "    \n",
    "    x = layers.Conv1D(filters=64, kernel_size=2, activation='relu')(inputs)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Conv1D(filters=128, kernel_size=2, activation='relu')(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.GRU(100, return_sequences=True)(x)\n",
    "    \n",
    "    attention = layers.Attention()([x, x])  # Self-attention (query = value = x)\n",
    "    x = layers.Concatenate()([x, attention])\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dense(output_days * output_features)(x)\n",
    "    \n",
    "    outputs = layers.Reshape((output_days, output_features))(x)\n",
    "    \n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    function_name = CNN_GRU_SA_model.__name__\n",
    "    \n",
    "    return model,function_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meta Model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "def base_training(model_function,\n",
    "                loading_path, \n",
    "                saving_path, \n",
    "                version_name, \n",
    "                seed = 42,\n",
    "                test_size = 0.8,\n",
    "                epochs = 20,\n",
    "                batch_size = 8,\n",
    "                shuffle=True, \n",
    "                metrics=['mae'],\n",
    "                loss = 'mean_squared_error',\n",
    "                #loss = custom_loss,\n",
    "                optimizer='adam',\n",
    "                window_size = window_size, \n",
    "                num_features = num_features, \n",
    "                output_days = output_days, \n",
    "                output_features = output_features):\n",
    "    \n",
    "    model_history = []\n",
    "    \n",
    "    #create folder to save the model\n",
    "    model_folder_path = os.path.join(saving_path, version_name, f\"_s-{seed}_t-{test_size}_e-{epochs}_b-{batch_size}_S-{shuffle}_m-{metrics}_l-{loss}_o-{optimizer}\")\n",
    "\n",
    "    os.makedirs(model_folder_path, exist_ok=True)\n",
    "    print(f\"Folder '{version_name}' is ready.\")\n",
    "\n",
    "\n",
    "    for window in window_size:\n",
    "        # Load the data\n",
    "        X = pd.read_pickle(loading_path + f\"X_{window}days_i.pkl\")\n",
    "        y = pd.read_pickle(loading_path + f\"y_{window}days_i.pkl\")\n",
    "        print(f\"Data for {window} days loaded.\")\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                            y, \n",
    "                                                            test_size=test_size, \n",
    "                                                            shuffle=shuffle, \n",
    "                                                            random_state=seed)\n",
    "        print(\"Data split into training and testing sets.\")\n",
    "\n",
    "        # Train the model\n",
    "        print(\"start training:\\n\")\n",
    "        model, name = model_function(window, \n",
    "                                     num_features, \n",
    "                                     output_days, \n",
    "                                     output_features)\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "        \n",
    "        history = model.fit(X_train, \n",
    "                            y_train, \n",
    "                            epochs=epochs, \n",
    "                            batch_size=batch_size, \n",
    "                            validation_data=(X_test, y_test), \n",
    "                            verbose=1)\n",
    "        \n",
    "        # Save the model    \n",
    "        model_save_path = os.path.join(model_folder_path, f\"{name}_{window}days.h5\")\n",
    "        model.save(model_save_path)\n",
    "        print(f\"Model trained on {window} days has been saved.\")\n",
    "\n",
    "        model_history.append(history)\n",
    "\n",
    "    return model_history\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_training_history(mdoel_history, window=window_size):   \n",
    "    for i in range(len(mdoel_history)):\n",
    "        plt.title(f\"Training and Validation Loss for {window[i]} days\")\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(mdoel_history[i].history['loss'], label='Training Loss')\n",
    "        plt.plot(mdoel_history[i].history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Loss over Epochs')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        # Plot MAE\n",
    "        plt.title(f\"Training and Validation MAE for {window[i]} days\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(mdoel_history[i].history['mae'], label='Training MAE')\n",
    "        plt.plot(mdoel_history[i].history['val_mae'], label='Validation MAE')\n",
    "        plt.title('MAE over Epochs')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('MAE')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder '20250128' is ready.\n",
      "Data for 7 days loaded.\n",
      "Data split into training and testing sets.\n",
      "start training:\n",
      "\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 7 and 2 for '{{node compile_loss/partial/mul}} = Mul[T=DT_FLOAT](compile_loss/partial/Const, compile_loss/partial/Square)' with input shapes: [7], [?,0,2].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[138], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m function_list \u001b[38;5;241m=\u001b[39m [baseline_LSTM_model, \n\u001b[1;32m      2\u001b[0m                  baseline_GRU_model, \n\u001b[1;32m      3\u001b[0m                  CNN_LSTM_model, \n\u001b[1;32m      4\u001b[0m                  CNN_GRU_model, \n\u001b[1;32m      5\u001b[0m                  CNN_LSTM_SA_model, \n\u001b[1;32m      6\u001b[0m                  CNN_GRU_SA_model]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_function \u001b[38;5;129;01min\u001b[39;00m function_list:\n\u001b[0;32m----> 8\u001b[0m     model_history \u001b[38;5;241m=\u001b[39m base_training(model_function, \n\u001b[1;32m      9\u001b[0m                                   loading_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/hoyinchui/Desktop/tbot-st-ta/Testing data/GLD_model_testing_data_i_v5_pkl/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     10\u001b[0m                                   saving_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/hoyinchui/Desktop/tbot-st-ta/saved models/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m                                   version_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m20250128\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m                                   )\n\u001b[1;32m     13\u001b[0m     plot_training_history(model_history)\n",
      "Cell \u001b[0;32mIn[137], line 55\u001b[0m, in \u001b[0;36mbase_training\u001b[0;34m(model_function, loading_path, saving_path, version_name, seed, test_size, epochs, batch_size, shuffle, metrics, loss, optimizer, window_size, num_features, output_days, output_features)\u001b[0m\n\u001b[1;32m     49\u001b[0m model, name \u001b[38;5;241m=\u001b[39m model_function(window, \n\u001b[1;32m     50\u001b[0m                              num_features, \n\u001b[1;32m     51\u001b[0m                              output_days, \n\u001b[1;32m     52\u001b[0m                              output_features)\n\u001b[1;32m     53\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39mloss, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n\u001b[0;32m---> 55\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train, \n\u001b[1;32m     56\u001b[0m                     y_train, \n\u001b[1;32m     57\u001b[0m                     epochs\u001b[38;5;241m=\u001b[39mepochs, \n\u001b[1;32m     58\u001b[0m                     batch_size\u001b[38;5;241m=\u001b[39mbatch_size, \n\u001b[1;32m     59\u001b[0m                     validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test), \n\u001b[1;32m     60\u001b[0m                     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Save the model    \u001b[39;00m\n\u001b[1;32m     63\u001b[0m model_save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_folder_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwindow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mdays.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[135], line 24\u001b[0m, in \u001b[0;36mtime_weighted_loss\u001b[0;34m(y_true, y_pred, weights, lambda_, gamma)\u001b[0m\n\u001b[1;32m     21\u001b[0m weights \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(weights, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Time-weighted MSE for min and max\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m mse_min \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(weights \u001b[38;5;241m*\u001b[39m tf\u001b[38;5;241m.\u001b[39msquare(y_true_min \u001b[38;5;241m-\u001b[39m y_pred_min))\n\u001b[1;32m     25\u001b[0m mse_max \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(weights \u001b[38;5;241m*\u001b[39m tf\u001b[38;5;241m.\u001b[39msquare(y_true_max \u001b[38;5;241m-\u001b[39m y_pred_max))\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Time-weighted min-max constraint penalty\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 7 and 2 for '{{node compile_loss/partial/mul}} = Mul[T=DT_FLOAT](compile_loss/partial/Const, compile_loss/partial/Square)' with input shapes: [7], [?,0,2]."
     ]
    }
   ],
   "source": [
    "function_list = [baseline_LSTM_model, \n",
    "                 baseline_GRU_model, \n",
    "                 CNN_LSTM_model, \n",
    "                 CNN_GRU_model, \n",
    "                 CNN_LSTM_SA_model, \n",
    "                 CNN_GRU_SA_model]\n",
    "for model_function in function_list:\n",
    "    model_history = base_training(model_function, \n",
    "                                  loading_path = \"/Users/hoyinchui/Desktop/tbot-st-ta/Testing data/GLD_model_testing_data_i_v5_pkl/\", \n",
    "                                  saving_path=\"/Users/hoyinchui/Desktop/tbot-st-ta/saved models/\",\n",
    "                                  version_name=\"20250128\"\n",
    "                                  )\n",
    "    plot_training_history(model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build ensemble model with meta mode (transfer learning/fine-tuning), since will do back propaggation through the ensemble layer all the way to the individual model, we can use multiple stock training data for the individual model, increase the generalization, and do the tuning with the target data, in the ensemble layer training part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "def ensemble_stacking (models_inputs, models_outputs, output_days, output_features, optimizer, loss, metrics):\n",
    "    merged_output = layers.concatenate(models_outputs, axis=-1)\n",
    "    #searching method for removing the last layer of the model, and directly inputting weight into stackinng model\n",
    "    \n",
    "    #stacking model\n",
    "    merged_output = layers.Dense(64, activation='relu')(merged_output)\n",
    "    merged_output = layers.Dense(output_days * output_features)(merged_output)\n",
    "    final_output = layers.Reshape((output_days, output_features))(merged_output)\n",
    "    ensemble_model = Model(inputs=models_inputs, outputs=final_output)\n",
    "    ensemble_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    return ensemble_model\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_weighting (models_inputs, models_outputs, output_days, output_features, optimizer, loss, metrics):\n",
    "    merged_output = layers.Add()(models_outputs)\n",
    "    merged_output = layers.Dense(output_days*output_features)(merged_output)\n",
    "    final_output = layers.Reshape((output_days, output_features))(merged_output)\n",
    "    ensemble_model = Model(inputs=models_inputs, outputs=final_output)\n",
    "    ensemble_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    return ensemble_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need more understanding on the MoE\n",
    "''' stacking is y_p = sum(w*y_i)\n",
    "    MoE is y_p = sum(g_i*y_i)\n",
    "    can add other function model, like anomaly detection, to the ensemble model, since most of the data is normal, the model can be used to detect the anomaly data(Event)\n",
    "'''\n",
    "\n",
    "def ensemble_MoE(models_inputs, models_outputs, output_days, output_features, optimizer, loss, metrics):\n",
    "    # Step 1: Concatenate the outputs of all the experts\n",
    "    concatenated_experts = layers.concatenate(models_outputs)\n",
    "    \n",
    "    # Step 2: Apply a gate to weight the expert outputs\n",
    "    gate = layers.Dense(len(models_outputs), activation='softmax')(concatenated_experts)\n",
    "    \n",
    "    # Step 3: Multiply the gate with the expert outputs\n",
    "    weighted_experts = [layers.Multiply()([gate[:, i:i+1], models_outputs[i]]) for i in range(len(models_outputs))]\n",
    "    \n",
    "    # Step 4: Sum the weighted expert outputs\n",
    "    final_expert_output = layers.Add()(weighted_experts)\n",
    "    \n",
    "    # Step 5: Reshape the final output to the desired shape\n",
    "    final_output = layers.Reshape((output_days, output_features))(final_expert_output)\n",
    "\n",
    "    # Step 6: Define the ensemble model\n",
    "    ensemble_model = models.Model(inputs=models_inputs, outputs=final_output)\n",
    "\n",
    "    # Step 7: Compile the model\n",
    "    ensemble_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    return ensemble_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to load models in provided path\n",
    "from tensorflow.keras.models import load_model\n",
    "def load_models(path, remove_last_layer=True):\n",
    "    orginal_models = []\n",
    "    models_outputs = []\n",
    "    models_inputs = []\n",
    "    models_order = []\n",
    "    for file in sorted(os.listdir(path)):\n",
    "        if file.endswith(\".h5\"):\n",
    "            model = load_model(os.path.join(path, file))\n",
    "            models_order.append(file)\n",
    "            print(f\"Model loaded: {os.path.join(path, file)}\")\n",
    "            orginal_models.append(load_model(os.path.join(path, file), compile=False))\n",
    "            if remove_last_layer:\n",
    "                try:\n",
    "                    output = model.layers[-2].output  # Use the second last layer as output\n",
    "                    model = Model(inputs=model.input, outputs=output)\n",
    "                    print(f\"Removed final layer from model: {os.path.join(path, file)}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error modifying model {os.path.join(path, file)}: {e}\")\n",
    "            models_inputs.append(model.input)\n",
    "            print(models_inputs)\n",
    "            models_outputs.append(model.output)\n",
    "    \n",
    "    \n",
    "    return orginal_models, models_inputs, models_outputs, models_order\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_model_training(models_inputs, models_outputs, output_days, output_features, model_type = \"stacking\", optimizer='adam', loss='mean_squared_error', metrics=['mae']):\n",
    "    if model_type == 'stacking':\n",
    "        ensemble_model = ensemble_stacking(models_inputs, models_outputs, output_days, output_features, optimizer, loss, metrics)\n",
    "    elif model_type == 'weighting':\n",
    "        ensemble_model = ensemble_weighting(models_inputs, models_outputs, output_days, output_features, optimizer, loss, metrics)\n",
    "    elif model_type == 'MoE':\n",
    "        ensemble_model = ensemble_MoE(models_inputs, models_outputs, output_days, output_features, optimizer, loss, metrics)\n",
    "    else:\n",
    "        print(\"Please provide a valid model type.\")\n",
    "        return None\n",
    "    return ensemble_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_GRU_SA_model_14days.h5\n",
      "Removed final layer from model: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_GRU_SA_model_14days.h5\n",
      "[<KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_45>]\n",
      "Model loaded: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_GRU_SA_model_30days.h5\n",
      "Removed final layer from model: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_GRU_SA_model_30days.h5\n",
      "[<KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_45>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_46>]\n",
      "Model loaded: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_GRU_SA_model_60days.h5\n",
      "Removed final layer from model: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_GRU_SA_model_60days.h5\n",
      "[<KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_45>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_46>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_47>]\n",
      "Model loaded: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_GRU_SA_model_7days.h5\n",
      "Removed final layer from model: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_GRU_SA_model_7days.h5\n",
      "[<KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_45>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_46>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_47>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_44>]\n",
      "Model loaded: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_GRU_model_14days.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed final layer from model: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_GRU_model_14days.h5\n",
      "[<KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_45>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_46>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_47>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_44>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_37>]\n",
      "Model loaded: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_GRU_model_30days.h5\n",
      "Removed final layer from model: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_GRU_model_30days.h5\n",
      "[<KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_45>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_46>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_47>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_44>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_37>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_38>]\n",
      "Model loaded: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_GRU_model_60days.h5\n",
      "Removed final layer from model: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_GRU_model_60days.h5\n",
      "[<KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_45>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_46>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_47>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_44>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_37>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_38>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_39>]\n",
      "Model loaded: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_GRU_model_7days.h5\n",
      "Removed final layer from model: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_GRU_model_7days.h5\n",
      "[<KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_45>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_46>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_47>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_44>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_37>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_38>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_39>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_36>]\n",
      "Model loaded: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_LSTM_SA_model_14days.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed final layer from model: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_LSTM_SA_model_14days.h5\n",
      "[<KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_45>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_46>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_47>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_44>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_37>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_38>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_39>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_36>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_41>]\n",
      "Model loaded: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_LSTM_SA_model_30days.h5\n",
      "Removed final layer from model: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_LSTM_SA_model_30days.h5\n",
      "[<KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_45>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_46>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_47>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_44>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_37>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_38>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_39>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_36>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_41>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_42>]\n",
      "Model loaded: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_LSTM_SA_model_60days.h5\n",
      "Removed final layer from model: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_LSTM_SA_model_60days.h5\n",
      "[<KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_45>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_46>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_47>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_44>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_37>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_38>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_39>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_36>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_41>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_42>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_43>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_LSTM_SA_model_7days.h5\n",
      "Removed final layer from model: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_LSTM_SA_model_7days.h5\n",
      "[<KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_45>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_46>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_47>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_44>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_37>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_38>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_39>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_36>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_41>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_42>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_43>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_40>]\n",
      "Model loaded: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_LSTM_model_14days.h5\n",
      "Removed final layer from model: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_LSTM_model_14days.h5\n",
      "[<KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_45>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_46>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_47>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_44>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_37>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_38>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_39>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_36>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_41>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_42>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_43>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_40>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_33>]\n",
      "Model loaded: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_LSTM_model_30days.h5\n",
      "Removed final layer from model: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_LSTM_model_30days.h5\n",
      "[<KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_45>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_46>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_47>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_44>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_37>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_38>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_39>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_36>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_41>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_42>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_43>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_40>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_33>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_34>]\n",
      "Model loaded: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_LSTM_model_60days.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed final layer from model: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_LSTM_model_60days.h5\n",
      "[<KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_45>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_46>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_47>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_44>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_37>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_38>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_39>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_36>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_41>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_42>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_43>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_40>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_33>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_34>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_35>]\n",
      "Model loaded: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_LSTM_model_7days.h5\n",
      "Removed final layer from model: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/CNN_LSTM_model_7days.h5\n",
      "[<KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_45>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_46>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_47>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_44>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_37>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_38>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_39>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_36>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_41>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_42>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_43>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_40>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_33>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_34>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_35>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_32>]\n",
      "Model loaded: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/baseline_GRU_model_14days.h5\n",
      "Removed final layer from model: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/baseline_GRU_model_14days.h5\n",
      "[<KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_45>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_46>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_47>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_44>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_37>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_38>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_39>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_36>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_41>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_42>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_43>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_40>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_33>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_34>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_35>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_32>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_53>]\n",
      "Model loaded: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/baseline_GRU_model_30days.h5\n",
      "Removed final layer from model: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/baseline_GRU_model_30days.h5\n",
      "[<KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_45>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_46>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_47>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_44>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_37>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_38>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_39>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_36>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_41>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_42>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_43>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_40>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_33>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_34>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_35>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_32>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_53>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_30>]\n",
      "Model loaded: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/baseline_GRU_model_60days.h5\n",
      "Removed final layer from model: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/baseline_GRU_model_60days.h5\n",
      "[<KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_45>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_46>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_47>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_44>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_37>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_38>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_39>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_36>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_41>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_42>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_43>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_40>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_33>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_34>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_35>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_32>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_53>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_30>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_31>]\n",
      "Model loaded: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/baseline_GRU_model_7days.h5\n",
      "Removed final layer from model: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/baseline_GRU_model_7days.h5\n",
      "[<KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_45>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_46>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_47>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_44>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_37>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_38>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_39>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_36>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_41>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_42>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_43>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_40>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_33>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_34>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_35>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_32>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_53>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_30>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_31>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_52>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/baseline_LSTM_model_14days.h5\n",
      "Removed final layer from model: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/baseline_LSTM_model_14days.h5\n",
      "[<KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_45>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_46>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_47>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_44>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_37>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_38>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_39>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_36>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_41>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_42>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_43>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_40>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_33>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_34>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_35>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_32>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_53>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_30>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_31>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_52>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_49>]\n",
      "Model loaded: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/baseline_LSTM_model_30days.h5\n",
      "Removed final layer from model: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/baseline_LSTM_model_30days.h5\n",
      "[<KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_45>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_46>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_47>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_44>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_37>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_38>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_39>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_36>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_41>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_42>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_43>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_40>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_33>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_34>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_35>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_32>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_53>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_30>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_31>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_52>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_49>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_50>]\n",
      "Model loaded: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/baseline_LSTM_model_60days.h5\n",
      "Removed final layer from model: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/baseline_LSTM_model_60days.h5\n",
      "[<KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_45>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_46>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_47>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_44>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_37>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_38>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_39>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_36>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_41>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_42>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_43>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_40>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_33>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_34>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_35>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_32>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_53>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_30>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_31>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_52>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_49>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_50>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_51>]\n",
      "Model loaded: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/baseline_LSTM_model_7days.h5\n",
      "Removed final layer from model: /Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam/baseline_LSTM_model_7days.h5\n",
      "[<KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_45>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_46>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_47>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_44>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_37>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_38>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_39>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_36>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_41>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_42>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_43>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_40>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_33>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_34>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_35>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_32>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_53>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_30>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_31>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_52>, <KerasTensor shape=(None, 14, 8), dtype=float32, sparse=False, name=input_layer_49>, <KerasTensor shape=(None, 30, 8), dtype=float32, sparse=False, name=input_layer_50>, <KerasTensor shape=(None, 60, 8), dtype=float32, sparse=False, name=input_layer_51>, <KerasTensor shape=(None, 7, 8), dtype=float32, sparse=False, name=input_layer_48>]\n"
     ]
    }
   ],
   "source": [
    "#load the whole folder of models (you might have multiple floders of models, then need multiple load_models function and do the selection in the next cell)\n",
    "orginal_models, models_inputs, models_outputs, models_order = load_models(\"/Users/hoyinchui/Desktop/tbot-st-ta/saved models/20250128/_s-42_t-0.8_e-20_b-8_S-True_m-['mae']_l-mean_squared_error_o-adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CNN_GRU_SA_model_14days.h5', 'CNN_GRU_SA_model_30days.h5', 'CNN_GRU_SA_model_60days.h5', 'CNN_GRU_SA_model_7days.h5', 'CNN_GRU_model_14days.h5', 'CNN_GRU_model_30days.h5', 'CNN_GRU_model_60days.h5', 'CNN_GRU_model_7days.h5', 'CNN_LSTM_SA_model_14days.h5', 'CNN_LSTM_SA_model_30days.h5', 'CNN_LSTM_SA_model_60days.h5', 'CNN_LSTM_SA_model_7days.h5', 'CNN_LSTM_model_14days.h5', 'CNN_LSTM_model_30days.h5', 'CNN_LSTM_model_60days.h5', 'CNN_LSTM_model_7days.h5', 'baseline_GRU_model_14days.h5', 'baseline_GRU_model_30days.h5', 'baseline_GRU_model_60days.h5', 'baseline_GRU_model_7days.h5', 'baseline_LSTM_model_14days.h5', 'baseline_LSTM_model_30days.h5', 'baseline_LSTM_model_60days.h5', 'baseline_LSTM_model_7days.h5']\n"
     ]
    }
   ],
   "source": [
    "#select the models(4 models Time-based) and ensemble method you want and feed into the ensemble traing function\n",
    "#if stargetry changed, the function and training set need to updatye too \n",
    "print(models_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#be aware of the order, it need to be 7, 14, 30, 60 from small to large\n",
    "models_inputs_selected = [models_inputs[3], models_inputs[0], models_inputs[1], models_inputs[2]]   \n",
    "models_outputs_selected = [models_outputs[3], models_outputs[0], models_outputs[1], models_outputs[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the models(4 models Time-based) and ensemble method you want and feed into the ensemble traing function\n",
    "#if stargetry changed, the function and training set need to updatye too \n",
    "ensemble_s_model = ensemble_model_training(models_inputs_selected, models_outputs_selected, output_days, output_features, model_type = \"stacking\", optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_w_model = ensemble_model_training(models_inputs_selected, models_outputs_selected, output_days, output_features, model_type = \"weighting\", optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_MoE_model = ensemble_model_training(models_inputs_selected, models_outputs_selected, output_days, output_features, model_type = \"MoE\", optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data for testing in ensemble model\n",
    "\n",
    "def load_data(window_size = window_size, path = f\"/Users/hoyinchui/Desktop/tbot-st-ta/Testing data/GLD_model_testing_data_pre_ens_Ai1_v3_pkl\", test_size = 0.8, shuffle = True, seed = 42):\n",
    "    all_X_train = []\n",
    "    all_X_test = []\n",
    "    all_y_train = []\n",
    "    all_y_test = []\n",
    "    \n",
    "    y = pd.read_pickle(f\"{path}/y_a.pkl\")\n",
    "    for window in window_size:\n",
    "        X = pd.read_pickle(f\"{path}/X_{window}days_a.pkl\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=shuffle, random_state=seed)\n",
    "        all_X_train.append(X_train)\n",
    "        all_X_test.append(X_test)\n",
    "        all_y_train.append(y_train)\n",
    "        all_y_test.append(y_test)\n",
    "    return all_X_train, all_X_test, all_y_train, all_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X_train, all_X_test, all_y_train, all_y_test = load_data(path = f\"/Users/hoyinchui/Desktop/tbot-st-ta/Testing data/GLD_model_testing_data_pre_ens_Ai1_v3_pkl\", test_size = 0.8, shuffle = True, seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the ensemble model\n",
    "def ensemble_model_fit(ensemble_model, all_X_train, all_y_train, epochs = 20, batch_size = 8):\n",
    "    history = ensemble_model.fit(all_X_train, all_y_train[0], epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0307 - mae: 0.0906\n",
      "Epoch 2/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 4.9231e-04 - mae: 0.0163\n",
      "Epoch 3/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 4.7505e-04 - mae: 0.0162\n",
      "Epoch 4/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 5.6417e-04 - mae: 0.0175\n",
      "Epoch 5/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.4949e-04 - mae: 0.0159\n",
      "Epoch 6/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.1725e-04 - mae: 0.0152\n",
      "Epoch 7/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 5.3108e-04 - mae: 0.0167\n",
      "Epoch 8/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 3.7259e-04 - mae: 0.0144\n",
      "Epoch 9/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.1055e-04 - mae: 0.0150\n",
      "Epoch 10/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.5056e-04 - mae: 0.0158\n",
      "Epoch 11/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.7371e-04 - mae: 0.0142\n",
      "Epoch 12/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 3.3060e-04 - mae: 0.0135\n",
      "Epoch 13/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.1015e-04 - mae: 0.0175\n",
      "Epoch 14/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.2535e-04 - mae: 0.0135\n",
      "Epoch 15/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 2.7843e-04 - mae: 0.0124\n",
      "Epoch 16/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 3.8601e-04 - mae: 0.0145\n",
      "Epoch 17/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.0195e-04 - mae: 0.0147\n",
      "Epoch 18/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 5.1995e-04 - mae: 0.0173\n",
      "Epoch 19/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 4.8247e-04 - mae: 0.0165\n",
      "Epoch 20/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.2634e-04 - mae: 0.0131\n"
     ]
    }
   ],
   "source": [
    "#traing the ensemble model\n",
    "ensemble_s_model_history = ensemble_model_fit(ensemble_s_model, all_X_train, all_y_train, epochs = 20, batch_size = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the following 3 cell can skip, theey are old version for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model and predict and save the prediction\n",
    "#for window in window_size:\n",
    "#    model = tf.keras.models.load_model(f\"CNN_LSTM_{window}days.h5\")\n",
    "#    y_pred = model.predict(X_test)\n",
    "#    pd.DataFrame(y_pred).to_csv(f\"y_pred_CNN_LSTM_{window}days.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting all windows prediction into the dataframe as X\n",
    "#import numpy as np\n",
    "#X_ensemble = pd.DataFrame()\n",
    "#for window in window_size:\n",
    "#    X_ensemble = pd.concat([X_ensemble, pd.read_csv(f\"y_pred_CNN_LSTM_{window}days.csv\")], axis=1)\n",
    "#    #combein the columns, so that can be used as input for the ensemble model\n",
    "#   X_ensemble = X_ensemble.applymap(lambda x: np.vstack(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They can combein in 1 for loop, I just split it for clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def train_test_split_ensemble(X,y,test_size=0.5, seed=42):    \n",
    "#    #split again for the prediction model and the ensemble model\n",
    "#    #Since we already shuffled the data, we can just split the data in half, and easaier to manage\n",
    "#    X_train_ensemble, X_test_ensemble, y_train_ensemble, y_test_ensemble = train_test_split(X, y, test_size=test_size, shuffle=False, random_state=seed)\n",
    "#    return X_train_ensemble, X_test_ensemble, y_train_ensemble, y_test_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_ensemble, X_test_ensemble, y_train_ensemble, y_test_ensemble = train_test_split_ensemble(X_ensemble, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Model (TBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.models import Model\n",
    "#def ensemble_CNN_LSTM(window_size, num_features):\n",
    "#    inputs = layers.Input(shape=(window_size, num_features))\n",
    "#    x = layers.Conv1D(filters=64, kernel_size=2, activation='relu')(inputs)\n",
    "#    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "#    x = layers.Conv1D(filters=128, kernel_size=2, activation='relu')(x)\n",
    "#    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "#    x = layers.LSTM(100)(x)\n",
    "#    model = Model(inputs=inputs, outputs=x)\n",
    "#    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def ensemble_s_models(window_size, num_features, output_days, output_features):\n",
    "#        models = []\n",
    "#    for window in window_size:\n",
    "#        model = ensemble_CNN_LSTM(window, num_features)\n",
    "#        models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def ensemble_MoE_models(window_size, num_features, output_days, output_features):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def ensemble_h_models(window_size, num_features, output_days, output_features):\n",
    "#    models = []\n",
    "#    for window in window_size:\n",
    "#        model = ensemble_CNN_LSTM(window, num_features)\n",
    "#        models.append(model)\n",
    "#    models_inputs = [model.input for model in models]\n",
    "#    models_outputs = [model.output for model in models]\n",
    "#   merged = layers.concatenate(models_outputs, axis=-1)\n",
    "#    merged_output = layers.Dense(output_days * output_features)(merged)\n",
    "#    final_output = layers.Reshape((output_days, output_features))(merged_output)\n",
    "#    ensemble_model = Model(inputs=models_inputs, outputs=final_output)\n",
    "#    ensemble_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "#\n",
    "#    return ensemble_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - loss: 0.0279 - mae: 0.1027 - val_loss: 5.5140e-04 - val_mae: 0.0176\n",
      "Epoch 2/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 5.2824e-04 - mae: 0.0169 - val_loss: 4.1390e-04 - val_mae: 0.0154\n",
      "Epoch 3/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 5.1239e-04 - mae: 0.0167 - val_loss: 4.6971e-04 - val_mae: 0.0162\n",
      "Epoch 4/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 4.3028e-04 - mae: 0.0155 - val_loss: 0.0011 - val_mae: 0.0263\n",
      "Epoch 5/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 7.6607e-04 - mae: 0.0210 - val_loss: 4.8477e-04 - val_mae: 0.0170\n",
      "Epoch 6/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 4.1826e-04 - mae: 0.0152 - val_loss: 3.3729e-04 - val_mae: 0.0135\n",
      "Epoch 7/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 3.9106e-04 - mae: 0.0147 - val_loss: 5.9622e-04 - val_mae: 0.0190\n",
      "Epoch 8/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 3.8556e-04 - mae: 0.0144 - val_loss: 3.2576e-04 - val_mae: 0.0133\n",
      "Epoch 9/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 3.8984e-04 - mae: 0.0145 - val_loss: 3.6576e-04 - val_mae: 0.0140\n",
      "Epoch 10/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 3.0942e-04 - mae: 0.0130 - val_loss: 0.0012 - val_mae: 0.0284\n",
      "Epoch 11/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 5.3522e-04 - mae: 0.0171 - val_loss: 3.7922e-04 - val_mae: 0.0143\n",
      "Epoch 12/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 4.1376e-04 - mae: 0.0154 - val_loss: 3.7486e-04 - val_mae: 0.0142\n",
      "Epoch 13/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 3.8007e-04 - mae: 0.0147 - val_loss: 3.5824e-04 - val_mae: 0.0140\n",
      "Epoch 14/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 3.6434e-04 - mae: 0.0141 - val_loss: 2.8506e-04 - val_mae: 0.0124\n",
      "Epoch 15/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 3.4567e-04 - mae: 0.0139 - val_loss: 6.9771e-04 - val_mae: 0.0211\n",
      "Epoch 16/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 3.9665e-04 - mae: 0.0147 - val_loss: 3.4478e-04 - val_mae: 0.0138\n",
      "Epoch 17/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 3.2562e-04 - mae: 0.0133 - val_loss: 2.6830e-04 - val_mae: 0.0118\n",
      "Epoch 18/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 3.8294e-04 - mae: 0.0148 - val_loss: 5.2331e-04 - val_mae: 0.0175\n",
      "Epoch 19/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 3.2525e-04 - mae: 0.0134 - val_loss: 7.1152e-04 - val_mae: 0.0207\n",
      "Epoch 20/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 4.0285e-04 - mae: 0.0149 - val_loss: 2.7196e-04 - val_mae: 0.0120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#import pandas as pd\n",
    "#seed = 42\n",
    "#test_size = 0.8 # we need to consider for the ensemble model's training and ttesting data, since it cannot use the same training data\n",
    "#epochs = 20\n",
    "#batch_size = 8\n",
    "#shuffle=True\n",
    "#all_X_train = []\n",
    "#all_X_test = []\n",
    "#all_y_train = []\n",
    "#all_y_test = []\n",
    "#\n",
    "#y = pd.read_pickle(f\"/Users/hoyinchui/Downloads/y_a.pkl\")\n",
    "#for window in window_size:\n",
    "#    X = pd.read_pickle(f\"/Users/hoyinchui/Downloads/X_{window}days_a.pkl\")\n",
    "#    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=shuffle, random_state=seed)\n",
    "#    all_X_train.append(X_train)\n",
    "#    all_X_test.append(X_test)\n",
    "#    all_y_train.append(y_train)\n",
    "#    all_y_test.append(y_test)\n",
    "#\n",
    "##ensemble_model = ensemble_h_models(window_size, num_features, output_days, output_features)\n",
    "##history = ensemble_model.fit(all_X_train, all_y_train[0], epochs=epochs, batch_size=batch_size, validation_data=(all_X_test, all_y_test[0]), verbose=1)\n",
    "##ensemble_model.save(f\"ensemble_CNN_LSTM.h5\")\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
