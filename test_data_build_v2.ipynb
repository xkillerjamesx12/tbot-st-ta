{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pickle"
      ],
      "metadata": {
        "id": "5C4UylDw4Ies"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_technical_indicators(df):\n",
        "    \"\"\"Calculate all required technical indicators\"\"\"\n",
        "    features = pd.DataFrame()\n",
        "\n",
        "    # Calendar Features\n",
        "    features['day_of_week'] = df['Date'].dt.dayofweek\n",
        "    features['day_of_month'] = df['Date'].dt.day\n",
        "    features['week_of_year'] = df['Date'].dt.isocalendar().week\n",
        "    features['month'] = df['Date'].dt.month\n",
        "    features['quarter'] = df['Date'].dt.quarter\n",
        "\n",
        "    # Period End Indicators\n",
        "    features['is_month_end'] = df['Date'].dt.is_month_end.astype(int)\n",
        "    features['is_quarter_end'] = df['Date'].dt.is_quarter_end.astype(int)\n",
        "    features['is_year_end'] = df['Date'].dt.is_year_end.astype(int)\n",
        "    features['days_to_month_end'] = df['Date'].dt.days_in_month - df['Date'].dt.day\n",
        "\n",
        "    # Add trading day information\n",
        "    features['is_trading_day'] = df['is_trading_day']\n",
        "\n",
        "    # Copy OHLCV data\n",
        "    features['Open'] = df['Open']\n",
        "    features['High'] = df['High']\n",
        "    features['Low'] = df['Low']\n",
        "    features['Close'] = df['Close']\n",
        "    features['Volume'] = df['Volume']\n",
        "\n",
        "    # # Include other columns if they exist\n",
        "    # if 'Dividends' in df.columns:\n",
        "    #     features['Dividends'] = df['Dividends']\n",
        "    # if 'Stock Splits' in df.columns:\n",
        "    #     features['Stock Splits'] = df['Stock Splits']\n",
        "    # if 'Capital Gains' in df.columns:\n",
        "    #     features['Capital Gains'] = df['Capital Gains']\n",
        "\n",
        "    # Define multiple timeframes for different market behaviors\n",
        "    short_term = [5, 14]           # Capture short-term movements\n",
        "    medium_term = [20, 50]         # Capture medium-term trends\n",
        "    long_term = [100, 200]         # Capture long-term trends\n",
        "\n",
        "    # 1. RSI (multiple periods)\n",
        "    delta = df['Close'].diff()\n",
        "    for period in [5, 14, 21, 50]:  # Added 5 for very short term, 50 for longer term\n",
        "        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
        "        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
        "        rs = gain / loss\n",
        "        features[f'RSI_{period}'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    # 2. Bollinger Bands Width (multiple periods)\n",
        "    for period in [10, 20, 50]:  # Added shorter and longer timeframes\n",
        "        ma = df['Close'].rolling(window=period).mean()\n",
        "        std = df['Close'].rolling(window=period).std()\n",
        "        features[f'BB_Width_{period}'] = ((ma + 2*std) - (ma - 2*std)) / ma\n",
        "\n",
        "    # 3. ADX (multiple periods)\n",
        "    high_low = df['High'] - df['Low']\n",
        "    high_close = np.abs(df['High'] - df['Close'].shift())\n",
        "    low_close = np.abs(df['Low'] - df['Close'].shift())\n",
        "    ranges = pd.concat([high_low, high_close, low_close], axis=1)\n",
        "    true_range = ranges.max(axis=1)\n",
        "\n",
        "    plus_dm = df['High'].diff()\n",
        "    minus_dm = df['Low'].diff()\n",
        "    plus_dm[plus_dm < 0] = 0\n",
        "    minus_dm[minus_dm > 0] = 0\n",
        "\n",
        "    for period in [14, 30, 50]:  # Added longer timeframes\n",
        "        tr_period = true_range.rolling(period).sum()\n",
        "        plus_dm_period = plus_dm.rolling(period).sum()\n",
        "        minus_dm_period = minus_dm.rolling(period).sum()\n",
        "\n",
        "        plus_di = 100 * (plus_dm_period / tr_period)\n",
        "        minus_di = 100 * (minus_dm_period / tr_period)\n",
        "        features[f'ADX_{period}'] = 100 * np.abs(plus_di - minus_di) / (plus_di + minus_di)\n",
        "\n",
        "    # 4. Volume ROC (multiple periods)\n",
        "    for period in [10, 20, 50]:  # Added shorter and longer timeframes\n",
        "        features[f'Volume_ROC_{period}'] = (\n",
        "            (df['Volume'] - df['Volume'].shift(period)) /\n",
        "            df['Volume'].shift(period)\n",
        "        ) * 100\n",
        "\n",
        "    # 5. Z-score of price (multiple periods)\n",
        "    for period in [10, 20, 50]:  # Added variety of timeframes\n",
        "        rolling_mean = df['Close'].rolling(window=period).mean()\n",
        "        rolling_std = df['Close'].rolling(window=period).std()\n",
        "        features[f'Price_Z_Score_{period}'] = (df['Close'] - rolling_mean) / rolling_std\n",
        "\n",
        "    # 6. Skewness (multiple periods)\n",
        "    for period in [10, 20, 50]:  # Added different timeframes\n",
        "        features[f'Skewness_{period}'] = df['Close'].rolling(period).skew()\n",
        "\n",
        "    # 7. Additional trend indicators\n",
        "    # Price distance from moving averages\n",
        "    for period in medium_term + long_term:\n",
        "        ma = df['Close'].rolling(window=period).mean()\n",
        "        features[f'Price_Distance_MA_{period}'] = (df['Close'] - ma) / ma * 100\n",
        "\n",
        "    # 8. Volatility ratios between timeframes\n",
        "    features['Volatility_Ratio_Short_Long'] = (\n",
        "        df['Close'].rolling(20).std() / df['Close'].rolling(100).std()\n",
        "    )\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "tk1WVT3R4MYy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data_with_features(csv_path):\n",
        "    \"\"\"\n",
        "    Prepare data with technical indicators, combining raw, normalized, and percentage change features\n",
        "    into a single DataFrame with appropriate prefixes\n",
        "\n",
        "    Returns:\n",
        "    - combined_features: DataFrame containing all feature types\n",
        "    - scaler: Fitted StandardScaler\n",
        "    \"\"\"\n",
        "\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(csv_path) # Fixed: Indentation was incorrect\n",
        "    df['Date'] = pd.to_datetime(df['Date'], utc=True)\n",
        "\n",
        "    # Add trading day feature\n",
        "    df['is_trading_day'] = df['Date'].dt.dayofweek.apply(lambda x: 1 if x < 5 else 0)\n",
        "\n",
        "    # Calculate technical indicators\n",
        "    features_df = calculate_technical_indicators(df)\n",
        "\n",
        "    # Handle missing values from technical indicator calculations\n",
        "    features_df = features_df.fillna(method='bfill').fillna(method='ffill')\n",
        "\n",
        "    # Create percentage change features\n",
        "    features_pct_change = pd.DataFrame()\n",
        "\n",
        "    # Calculate percentage changes for price-based columns\n",
        "    price_cols = ['Open', 'High', 'Low', 'Close']\n",
        "    for col in price_cols:\n",
        "        if col in features_df.columns:\n",
        "            features_pct_change[f'{col}_pct_change'] = features_df[col].pct_change()\n",
        "            features_pct_change[f'{col}_pct_change_1d'] = features_df[col].pct_change(periods=1)\n",
        "            features_pct_change[f'{col}_pct_change_5d'] = features_df[col].pct_change(periods=5)\n",
        "            features_pct_change[f'{col}_pct_change_20d'] = features_df[col].pct_change(periods=20)\n",
        "\n",
        "    # Calculate percentage changes for volume\n",
        "    if 'Volume' in features_df.columns:\n",
        "        features_pct_change['Volume_pct_change'] = features_df['Volume'].pct_change()\n",
        "        features_pct_change['Volume_pct_change_5d'] = features_df['Volume'].pct_change(periods=5)\n",
        "        features_pct_change['Volume_pct_change_20d'] = features_df['Volume'].pct_change(periods=20)\n",
        "\n",
        "    # Calculate percentage changes for technical indicators\n",
        "    technical_cols = [col for col in features_df.columns\n",
        "                     if any(indicator in col for indicator in ['RSI', 'BB', 'ADX', 'ROC'])]\n",
        "    for col in technical_cols:\n",
        "        features_pct_change[f'{col}_pct_change'] = features_df[col].pct_change()\n",
        "\n",
        "    # Handle missing values in percentage changes\n",
        "    features_pct_change = features_pct_change.fillna(method='bfill').fillna(method='ffill')\n",
        "\n",
        "    # Don't normalize calendar features\n",
        "    calendar_cols = ['day_of_week', 'day_of_month', 'week_of_year', 'month', 'quarter',\n",
        "                    'is_month_end', 'is_quarter_end', 'is_year_end', 'days_to_month_end']\n",
        "\n",
        "    # Separate features to normalize\n",
        "    features_to_normalize = features_df.drop(columns=calendar_cols, errors='ignore')\n",
        "\n",
        "    # Standardize features (excluding calendar features)\n",
        "    scaler = StandardScaler()\n",
        "    normalized_data = scaler.fit_transform(features_to_normalize)\n",
        "    features_normalized = pd.DataFrame(normalized_data, columns=features_to_normalize.columns)\n",
        "\n",
        "    # Create combined DataFrame\n",
        "    combined_features = pd.DataFrame()\n",
        "\n",
        "    # Add raw features with 'raw_' prefix (except calendar features)\n",
        "    for col in features_df.columns:\n",
        "        if col not in calendar_cols:\n",
        "            combined_features[f'raw_{col}'] = features_df[col]\n",
        "        else:\n",
        "            combined_features[col] = features_df[col]  # Calendar features without prefix\n",
        "\n",
        "    # Add normalized features with 'norm_' prefix\n",
        "    for col in features_normalized.columns:\n",
        "        if col not in calendar_cols:\n",
        "            combined_features[f'norm_{col}'] = features_normalized[col]\n",
        "\n",
        "    # Add percentage change features with 'pct_' prefix\n",
        "    for col in features_pct_change.columns:\n",
        "        combined_features[f'pct_{col}'] = features_pct_change[col]\n",
        "\n",
        "    return combined_features, scaler"
      ],
      "metadata": {
        "id": "fV7WqUU04Qt8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "source": [
        "def prepare_data_with_features(csv_path):\n",
        "    \"\"\"\n",
        "    Prepare data with technical indicators, combining raw, normalized, and percentage change features\n",
        "    into a single DataFrame with appropriate prefixes\n",
        "\n",
        "    Returns:\n",
        "    - combined_features: DataFrame containing all feature types\n",
        "    - scaler: Fitted StandardScaler\n",
        "    \"\"\"\n",
        "\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(csv_path) # Fixed: Indentation was incorrect\n",
        "    df['Date'] = pd.to_datetime(df['Date'], utc=True)\n",
        "\n",
        "    # Add trading day feature\n",
        "    df['is_trading_day'] = df['Date'].dt.dayofweek.apply(lambda x: 1 if x < 5 else 0)\n",
        "\n",
        "    # Calculate technical indicators\n",
        "    features_df = calculate_technical_indicators(df)\n",
        "\n",
        "    # Handle missing values from technical indicator calculations\n",
        "    features_df = features_df.fillna(method='bfill').fillna(method='ffill')\n",
        "\n",
        "    # Create percentage change features\n",
        "    features_pct_change = pd.DataFrame()\n",
        "\n",
        "    # Calculate percentage changes for price-based columns\n",
        "    price_cols = ['Open', 'High', 'Low', 'Close']\n",
        "    for col in price_cols:\n",
        "        if col in features_df.columns:\n",
        "            features_pct_change[f'{col}_pct_change'] = features_df[col].pct_change()\n",
        "            features_pct_change[f'{col}_pct_change_1d'] = features_df[col].pct_change(periods=1)\n",
        "            features_pct_change[f'{col}_pct_change_5d'] = features_df[col].pct_change(periods=5)\n",
        "            features_pct_change[f'{col}_pct_change_20d'] = features_df[col].pct_change(periods=20)\n",
        "\n",
        "    # Calculate percentage changes for volume\n",
        "    if 'Volume' in features_df.columns:\n",
        "        features_pct_change['Volume_pct_change'] = features_df['Volume'].pct_change()\n",
        "        features_pct_change['Volume_pct_change_5d'] = features_df['Volume'].pct_change(periods=5)\n",
        "        features_pct_change['Volume_pct_change_20d'] = features_df['Volume'].pct_change(periods=20)\n",
        "\n",
        "    # Calculate percentage changes for technical indicators\n",
        "    technical_cols = [col for col in features_df.columns\n",
        "                     if any(indicator in col for indicator in ['RSI', 'BB', 'ADX', 'ROC'])]\n",
        "    for col in technical_cols:\n",
        "        features_pct_change[f'{col}_pct_change'] = features_df[col].pct_change()\n",
        "\n",
        "    # Handle missing values in percentage changes\n",
        "    features_pct_change = features_pct_change.fillna(method='bfill').fillna(method='ffill')\n",
        "\n",
        "    # Don't normalize calendar features\n",
        "    calendar_cols = ['day_of_week', 'day_of_month', 'week_of_year', 'month', 'quarter',\n",
        "                    'is_month_end', 'is_quarter_end', 'is_year_end', 'days_to_month_end']\n",
        "\n",
        "    # Separate features to normalize\n",
        "    features_to_normalize = features_df.drop(columns=calendar_cols, errors='ignore')\n",
        "\n",
        "    # Standardize features (excluding calendar features)\n",
        "    scaler = StandardScaler()\n",
        "    normalized_data = scaler.fit_transform(features_to_normalize)\n",
        "    features_normalized = pd.DataFrame(normalized_data, columns=features_to_normalize.columns)\n",
        "\n",
        "    # Create combined DataFrame\n",
        "    combined_features = pd.DataFrame()\n",
        "\n",
        "    # Add raw features with 'raw_' prefix (except calendar features)\n",
        "    for col in features_df.columns:\n",
        "        if col not in calendar_cols:\n",
        "            combined_features[f'raw_{col}'] = features_df[col]\n",
        "        else:\n",
        "            combined_features[col] = features_df[col]  # Calendar features without prefix\n",
        "\n",
        "    # Add normalized features with 'norm_' prefix\n",
        "    for col in features_normalized.columns:\n",
        "        if col not in calendar_cols:\n",
        "            combined_features[f'norm_{col}'] = features_normalized[col]\n",
        "\n",
        "    # Add percentage change features with 'pct_' prefix\n",
        "    for col in features_pct_change.columns:\n",
        "        combined_features[f'pct_{col}'] = features_pct_change[col]\n",
        "\n",
        "    return combined_features, scaler"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "LwYhtNPUMtPb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sliding_window_data(data, window_size, target_days):\n",
        "    \"\"\"Create sliding window data for individual prediction model\"\"\"\n",
        "    X, y = [], []\n",
        "\n",
        "    for i in range(len(data) - window_size - target_days + 1):\n",
        "        X_window = data[i:i + window_size]\n",
        "        y_target = data[i + window_size:i + window_size + target_days, 1:3]\n",
        "\n",
        "        X.append(X_window)\n",
        "        y.append(y_target)\n",
        "\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "HBI9EzNY4Ufi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sliding_window_data_a(i_from_window_size_loop, data, window_size, max_window_size, target_days):\n",
        "    \"\"\"Create sliding window data for all-in-1 model\"\"\"\n",
        "    X, y = [], []\n",
        "\n",
        "    for i in range(max_window_size, len(data) - target_days + 1):\n",
        "        if i_from_window_size_loop == 0:\n",
        "            y_target = data[i:i + target_days, 1:3]\n",
        "            y.append(y_target)\n",
        "\n",
        "        X_window = data[i-window_size:i]\n",
        "        X.append(X_window)\n",
        "\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "gR6L1XiY4Wcr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main execution\n",
        "def process_data(csv_path, save_path_prefix):\n",
        "    \"\"\"Process data and save results with combined features\"\"\"\n",
        "    # Prepare features\n",
        "    combined_features, scaler = prepare_data_with_features(csv_path)\n",
        "\n",
        "    window_sizes = [7, 14, 30, 60]\n",
        "    target_days = 7\n",
        "\n",
        "    # Save scaler and features for later use\n",
        "    with open(f'{save_path_prefix}_scaler.pkl', 'wb') as file:\n",
        "        pickle.dump(scaler, file)\n",
        "    with open(f'{save_path_prefix}_combined_features.pkl', 'wb') as file:\n",
        "        pickle.dump(combined_features, file)\n",
        "\n",
        "    # Print feature information\n",
        "    print(\"\\nFeature set information:\")\n",
        "    print(f\"Total number of features: {combined_features.shape[1]}\")\n",
        "    print(\"\\nFeature groups:\")\n",
        "    raw_features = [col for col in combined_features.columns if col.startswith('raw_')]\n",
        "    norm_features = [col for col in combined_features.columns if col.startswith('norm_')]\n",
        "    pct_features = [col for col in combined_features.columns if col.startswith('pct_')]\n",
        "    calendar_features = [col for col in combined_features.columns\n",
        "                        if not any(col.startswith(prefix) for prefix in ['raw_', 'norm_', 'pct_'])]\n",
        "\n",
        "    print(f\"Raw features: {len(raw_features)}\")\n",
        "    print(f\"Normalized features: {len(norm_features)}\")\n",
        "    print(f\"Percentage change features: {len(pct_features)}\")\n",
        "    print(f\"Calendar features: {len(calendar_features)}\")\n",
        "\n",
        "    # Individual prediction model data\n",
        "    print(\"\\nCreating individual prediction model data...\")\n",
        "    for window_size in window_sizes:\n",
        "        X, y = create_sliding_window_data(combined_features.values, window_size, target_days)\n",
        "        print(f\"\\nWindow size: {window_size} - X: {X.shape}, y: {y.shape}\")\n",
        "\n",
        "        with open(f'{save_path_prefix}_X_{window_size}days_i.pkl', 'wb') as file:\n",
        "            pickle.dump(X, file)\n",
        "        print(\"Done Saving X\")\n",
        "\n",
        "        with open(f'{save_path_prefix}_y_{window_size}days_i.pkl', 'wb') as file:\n",
        "            pickle.dump(y, file)\n",
        "        print(\"Done Saving y\")\n",
        "\n",
        "    # All-in-1 model data\n",
        "    print(\"\\nCreating all-in-1 model data...\")\n",
        "    max_window_size = max(window_sizes)\n",
        "    for i, window_size in enumerate(window_sizes):\n",
        "        X, y = create_sliding_window_data_a(i, combined_features.values, window_size, max_window_size, target_days)\n",
        "        print(f\"\\nWindow size: {window_size} - X: {X.shape}, y: {y.shape}\")\n",
        "\n",
        "        with open(f'{save_path_prefix}_X_{window_size}days_a.pkl', 'wb') as file:\n",
        "            pickle.dump(X, file)\n",
        "        print(\"Done Saving X\")\n",
        "\n",
        "        if i == 0:\n",
        "            with open(f'{save_path_prefix}_y_a.pkl', 'wb') as file:\n",
        "                pickle.dump(y, file)\n",
        "            print(\"Done Saving y\")\n",
        "\n",
        "    # Save feature names for reference\n",
        "    feature_info = {\n",
        "        'raw_features': raw_features,\n",
        "        'normalized_features': norm_features,\n",
        "        'percentage_features': pct_features,\n",
        "        'calendar_features': calendar_features\n",
        "    }\n",
        "    with open(f'{save_path_prefix}_feature_info.pkl', 'wb') as file:\n",
        "        pickle.dump(feature_info, file)\n"
      ],
      "metadata": {
        "id": "VTiULyrT4Y5-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = \"GLD-20041118-20250119.csv\"  # Update with your CSV path\n",
        "save_path_prefix = \"processed_data\"      # Update with your desired save path prefix\n",
        "process_data(csv_path, save_path_prefix)"
      ],
      "metadata": {
        "id": "oR0htgAR5YPZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2dab11d-a722-411c-a97b-3ee31789a3c2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-8e4d6634e4cc>:22: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  features_df = features_df.fillna(method='bfill').fillna(method='ffill')\n",
            "<ipython-input-4-8e4d6634e4cc>:49: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  features_pct_change = features_pct_change.fillna(method='bfill').fillna(method='ffill')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature set information:\n",
            "Total number of features: 101\n",
            "\n",
            "Feature groups:\n",
            "Raw features: 30\n",
            "Normalized features: 30\n",
            "Percentage change features: 32\n",
            "Calendar features: 9\n",
            "\n",
            "Creating individual prediction model data...\n",
            "\n",
            "Window size: 7 - X: (5061, 7, 101), y: (5061, 7, 2)\n",
            "Done Saving X\n",
            "Done Saving y\n",
            "\n",
            "Window size: 14 - X: (5054, 14, 101), y: (5054, 7, 2)\n",
            "Done Saving X\n",
            "Done Saving y\n",
            "\n",
            "Window size: 30 - X: (5038, 30, 101), y: (5038, 7, 2)\n",
            "Done Saving X\n",
            "Done Saving y\n",
            "\n",
            "Window size: 60 - X: (5008, 60, 101), y: (5008, 7, 2)\n",
            "Done Saving X\n",
            "Done Saving y\n",
            "\n",
            "Creating all-in-1 model data...\n",
            "\n",
            "Window size: 7 - X: (5008, 7, 101), y: (5008, 7, 2)\n",
            "Done Saving X\n",
            "Done Saving y\n",
            "\n",
            "Window size: 14 - X: (5008, 14, 101), y: (0,)\n",
            "Done Saving X\n",
            "\n",
            "Window size: 30 - X: (5008, 30, 101), y: (0,)\n",
            "Done Saving X\n",
            "\n",
            "Window size: 60 - X: (5008, 60, 101), y: (0,)\n",
            "Done Saving X\n"
          ]
        }
      ]
    }
  ]
}